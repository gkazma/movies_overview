{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>overview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Comedy, Drama, Romance]</td>\n",
       "      <td>Beautiful chanteuse 'Bijou' (Marlene Dietrich)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Action, Crime, Drama, Thriller]</td>\n",
       "      <td>In a post-apocalyptic world ravaged by feuding...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Drama, Romance, TV Movie, Western]</td>\n",
       "      <td>Marty is a 19 year old pioneer woman, recently...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Action, Comedy]</td>\n",
       "      <td>A couple of fumbling best friends run a privat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Comedy, Romance, TV Movie]</td>\n",
       "      <td>One woman's unexpected race to the altar teach...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                genres   \n",
       "0             [Comedy, Drama, Romance]  \\\n",
       "1     [Action, Crime, Drama, Thriller]   \n",
       "2  [Drama, Romance, TV Movie, Western]   \n",
       "3                     [Action, Comedy]   \n",
       "4          [Comedy, Romance, TV Movie]   \n",
       "\n",
       "                                            overview  \n",
       "0  Beautiful chanteuse 'Bijou' (Marlene Dietrich)...  \n",
       "1  In a post-apocalyptic world ravaged by feuding...  \n",
       "2  Marty is a 19 year old pioneer woman, recently...  \n",
       "3  A couple of fumbling best friends run a privat...  \n",
       "4  One woman's unexpected race to the altar teach...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are multiple genres per movie\n",
    "train_df = pd.read_csv(\"dataset/train_data.csv\",usecols=['genres', 'overview'], converters={\"genres\":literal_eval})\n",
    "test_df = pd.read_csv(\"dataset/test_data.csv\",usecols=['genres', 'overview'], converters={\"genres\":literal_eval})\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial train and test split.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_split = 0.1\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "    train_df,\n",
    "    test_size=test_split,\n",
    "    stratify=train_df[\"genres\"].values,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary:\n",
      "\n",
      "['Drama', 'Comedy', 'Thriller', 'Romance', 'Action', 'Horror', 'Crime', 'Documentary', 'Adventure', 'Science Fiction', 'Family', 'Mystery', 'Fantasy', 'Animation', 'Music', 'Foreign', 'History', 'War', 'Western', 'TV Movie']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "genres = tf.ragged.constant(train_df[\"genres\"].values)\n",
    "lookup = tf.keras.layers.StringLookup(output_mode=\"multi_hot\", num_oov_indices=0)\n",
    "lookup.adapt(genres)\n",
    "vocab = lookup.get_vocabulary()\n",
    "\n",
    "print(\"Vocabulary:\\n\")\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(dataframe, is_train=True):\n",
    "    labels = tf.ragged.constant(dataframe[\"genres\"].values)\n",
    "    label_binarized = lookup(labels).numpy()\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (dataframe[\"overview\"].values, label_binarized)\n",
    "    )\n",
    "    dataset = dataset.shuffle(batch_size * 10) if is_train else dataset\n",
    "    return dataset.batch(batch_size)\n",
    "\n",
    "\n",
    "train_dataset = make_dataset(train_df, is_train=True)\n",
    "validation_dataset = make_dataset(val_df, is_train=False)\n",
    "test_dataset = make_dataset(test_df, is_train=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "def make_mlp_model(text_vectorizer):\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            tf.keras.Input(shape=(1,), dtype=tf.string, name='text'),\n",
    "            text_vectorizer,\n",
    "            layers.Dense(64, activation=\"relu\"),\n",
    "            layers.Dense(32, activation=\"relu\"),\n",
    "            layers.Dense(lookup.vocabulary_size(), activation=\"sigmoid\"),\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def make_conv_model(text_vectorizer):\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            tf.keras.Input(shape=(1,), dtype=tf.string, name='text'),\n",
    "            text_vectorizer,\n",
    "            layers.Lambda(lambda x: tf.cast(x, \"float32\")),\n",
    "            layers.Reshape((-1, 1)),\n",
    "            layers.Conv1D(64, 3, activation='sigmoid'),\n",
    "            layers.Conv1D(32, 3, activation='sigmoid'),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(lookup.vocabulary_size(), activation=\"sigmoid\"),\n",
    "        ]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Util Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_result(history, item):\n",
    "    plt.plot(history.history[item], label=item)\n",
    "    plt.plot(history.history[\"val_\" + item], label=\"val_\" + item)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(item)\n",
    "    plt.title(\"Train and Validation {} Over Epochs\".format(item), fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Vectorization with MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizer = layers.TextVectorization(output_mode=\"tf_idf\")\n",
    "text_vectorizer.adapt(train_dataset.map(lambda text, label: text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - 14s 58ms/step - loss: 0.2964 - binary_accuracy: 0.9006 - categorical_accuracy: 0.4824 - accuracy: 0.0000e+00 - auc_1: 0.7936 - f1_score: 0.1736 - precision_1: 0.5522 - recall_1: 0.2497 - val_loss: 0.2233 - val_binary_accuracy: 0.9175 - val_categorical_accuracy: 0.5356 - val_accuracy: 0.0000e+00 - val_auc_1: 0.8838 - val_f1_score: 0.2645 - val_precision_1: 0.6868 - val_recall_1: 0.3732\n",
      "Epoch 2/2\n",
      "235/235 [==============================] - 13s 55ms/step - loss: 0.1428 - binary_accuracy: 0.9461 - categorical_accuracy: 0.6125 - accuracy: 2.3273e-05 - auc_1: 0.9581 - f1_score: 0.3927 - precision_1: 0.8398 - recall_1: 0.5968 - val_loss: 0.2318 - val_binary_accuracy: 0.9187 - val_categorical_accuracy: 0.5111 - val_accuracy: 1.4961e-05 - val_auc_1: 0.8862 - val_f1_score: 0.3013 - val_precision_1: 0.6530 - val_recall_1: 0.4582\n",
      "33/33 [==============================] - 0s 15ms/step - loss: 0.2242 - binary_accuracy: 0.9181 - categorical_accuracy: 0.5337 - accuracy: 0.0000e+00 - auc_1: 0.8822 - f1_score: 0.2619 - precision_1: 0.6889 - recall_1: 0.3769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.22423888742923737,\n",
       " 0.9180562496185303,\n",
       " 0.5336887836456299,\n",
       " 0.0,\n",
       " 0.8821662068367004,\n",
       " 0.2619091272354126,\n",
       " 0.6888936758041382,\n",
       " 0.3769357204437256]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 2\n",
    "\n",
    "model = make_mlp_model(text_vectorizer)\n",
    "\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\", \n",
    "    optimizer=\"adam\",\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy(), \n",
    "             tf.keras.metrics.CategoricalAccuracy(), \n",
    "             tf.keras.metrics.Accuracy(), \n",
    "             tf.keras.metrics.AUC(), \n",
    "             tf.keras.metrics.F1Score(average='macro'), \n",
    "             tf.keras.metrics.Precision(), \n",
    "             tf.keras.metrics.Recall()]\n",
    ")\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=0,\n",
    "    verbose=0,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset, validation_data=validation_dataset, epochs=epochs, callbacks=[early_stopping_monitor], verbose=1\n",
    ")\n",
    "\n",
    "# plot_result(history, \"loss\")\n",
    "# plot_result(history, \"binary_accuracy\")\n",
    "\n",
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seqlen = 150\n",
    "text_vectorizer = layers.TextVectorization(output_sequence_length=max_seqlen, output_mode=\"int\")\n",
    "text_vectorizer.adapt(train_dataset.map(lambda text, label: text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "235/235 [==============================] - 4s 16ms/step - loss: 0.2934 - binary_accuracy: 0.8927 - categorical_accuracy: 0.4688 - accuracy: 0.0000e+00 - auc_3: 0.7530 - f1_score: 0.0331 - precision_3: 0.4134 - recall_3: 0.0676 - val_loss: 0.2854 - val_binary_accuracy: 0.8960 - val_categorical_accuracy: 0.4734 - val_accuracy: 0.0000e+00 - val_auc_3: 0.7654 - val_f1_score: 0.0321 - val_precision_3: 0.4885 - val_recall_3: 0.1017\n",
      "Epoch 2/2\n",
      "235/235 [==============================] - 3s 14ms/step - loss: 0.2866 - binary_accuracy: 0.8952 - categorical_accuracy: 0.4737 - accuracy: 0.0000e+00 - auc_3: 0.7643 - f1_score: 0.0322 - precision_3: 0.4837 - recall_3: 0.0655 - val_loss: 0.2851 - val_binary_accuracy: 0.8965 - val_categorical_accuracy: 0.4734 - val_accuracy: 0.0000e+00 - val_auc_3: 0.7635 - val_f1_score: 0.0321 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2844 - binary_accuracy: 0.8967 - categorical_accuracy: 0.4716 - accuracy: 0.0000e+00 - auc_3: 0.7651 - f1_score: 0.0320 - precision_3: 0.0000e+00 - recall_3: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.28439009189605713,\n",
       " 0.896703839302063,\n",
       " 0.47164323925971985,\n",
       " 0.0,\n",
       " 0.7651023864746094,\n",
       " 0.032048750668764114,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 2\n",
    "\n",
    "model = make_conv_model(text_vectorizer)\n",
    "\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\", \n",
    "    optimizer=\"adam\",\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy(), \n",
    "             tf.keras.metrics.CategoricalAccuracy(), \n",
    "             tf.keras.metrics.Accuracy(), \n",
    "             tf.keras.metrics.AUC(), \n",
    "             tf.keras.metrics.F1Score(average='macro'), \n",
    "             tf.keras.metrics.Precision(), \n",
    "             tf.keras.metrics.Recall()]\n",
    ")\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=0,\n",
    "    verbose=0,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset, validation_data=validation_dataset, epochs=epochs, callbacks=[early_stopping_monitor], verbose=1\n",
    ")\n",
    "\n",
    "# plot_result(history, \"loss\")\n",
    "# plot_result(history, \"binary_accuracy\")\n",
    "\n",
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(iter(train_dataset))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([128, 150])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vectorizer(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "movies",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
