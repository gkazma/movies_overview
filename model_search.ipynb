{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overview</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>During her wedding ceremony, Rachel notices Lu...</td>\n",
       "      <td>[Comedy, Drama, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>While doing undercover work in a mental hospit...</td>\n",
       "      <td>[Adventure, Horror]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Depressed single mom Adele and her son Henry o...</td>\n",
       "      <td>[Drama]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jenny is young. Her life is over. She killed s...</td>\n",
       "      <td>[Drama, Music]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Raised in a single parent family by his mother...</td>\n",
       "      <td>[Drama]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            overview                    genres\n",
       "0  During her wedding ceremony, Rachel notices Lu...  [Comedy, Drama, Romance]\n",
       "1  While doing undercover work in a mental hospit...       [Adventure, Horror]\n",
       "2  Depressed single mom Adele and her son Henry o...                   [Drama]\n",
       "3  Jenny is young. Her life is over. She killed s...            [Drama, Music]\n",
       "4  Raised in a single parent family by his mother...                   [Drama]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are multiple genres per movie\n",
    "train_df = pd.read_csv(\"dataset/train_data.csv\",usecols=['genres', 'overview'], converters={\"genres\":literal_eval})\n",
    "test_df = pd.read_csv(\"dataset/test_data.csv\",usecols=['genres', 'overview'], converters={\"genres\":literal_eval})\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial train and test split.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_split = 0.1\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "    train_df,\n",
    "    test_size=test_split,\n",
    "    stratify=train_df[\"genres\"].values,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # There are multiple genres per movie\n",
    "# train_df = pd.read_csv(\"dataset/train_data.csv\",usecols=['genres', 'overview'], converters={\"genres\":literal_eval})[:1000]\n",
    "# test_df = pd.read_csv(\"dataset/test_data.csv\",usecols=['genres', 'overview'], converters={\"genres\":literal_eval})[:100]\n",
    "# train_df.head()\n",
    "\n",
    "# # Initial train and test split.\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# test_split = 0.1\n",
    "\n",
    "# train_df, val_df = train_test_split(\n",
    "#     train_df,\n",
    "#     test_size=test_split,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary:\n",
      "\n",
      "['Drama', 'Comedy', 'Thriller', 'Romance', 'Action', 'Horror', 'Crime', 'Documentary', 'Adventure', 'Science Fiction', 'Family', 'Mystery', 'Fantasy', 'Animation', 'Music', 'Foreign', 'History', 'War', 'Western', 'TV Movie']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "genres = tf.ragged.constant(train_df[\"genres\"].values)\n",
    "lookup = tf.keras.layers.StringLookup(output_mode=\"multi_hot\", num_oov_indices=0)\n",
    "lookup.adapt(genres)\n",
    "vocab = lookup.get_vocabulary()\n",
    "\n",
    "print(\"Vocabulary:\\n\")\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(dataframe, is_train=True):\n",
    "    labels = tf.ragged.constant(dataframe[\"genres\"].values)\n",
    "    label_binarized = lookup(labels).numpy()\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (dataframe[\"overview\"].values, label_binarized)\n",
    "    )\n",
    "    dataset = dataset.shuffle(batch_size * 10) if is_train else dataset\n",
    "    return dataset.batch(batch_size)\n",
    "\n",
    "\n",
    "train_dataset = make_dataset(train_df, is_train=True)\n",
    "validation_dataset = make_dataset(val_df, is_train=False)\n",
    "test_dataset = make_dataset(test_df, is_train=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "def make_mlp_model(text_vectorizer):\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            tf.keras.Input(shape=(1,), dtype=tf.string, name='text'),\n",
    "            text_vectorizer,\n",
    "            layers.Dense(64, activation=\"relu\"),\n",
    "            layers.Dense(32, activation=\"relu\"),\n",
    "            layers.Dense(lookup.vocabulary_size(), activation=\"sigmoid\"),\n",
    "        ],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def make_conv_model(text_vectorizer):\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            tf.keras.Input(shape=(1,), dtype=tf.string, name='text'),\n",
    "            text_vectorizer,\n",
    "            layers.Lambda(lambda x: tf.cast(x, \"float32\")),\n",
    "            layers.Reshape((-1, 1)),\n",
    "            layers.Conv1D(64, 3, activation='sigmoid'),\n",
    "            layers.Conv1D(32, 3, activation='sigmoid'),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(lookup.vocabulary_size(), activation=\"sigmoid\"),\n",
    "        ],\n",
    "        \n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def make_lstm_model(text_vectorizer):\n",
    "    model = tf.keras.Sequential([\n",
    "        text_vectorizer,\n",
    "        layers.Embedding(\n",
    "            input_dim=len(text_vectorizer.get_vocabulary()),\n",
    "            output_dim=64,\n",
    "            mask_zero=True),\n",
    "        layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(lookup.vocabulary_size(), activation=\"sigmoid\"),\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "\n",
    "def make_stacked_lstm_model(text_vectorizer):\n",
    "    model = tf.keras.Sequential([\n",
    "        text_vectorizer,\n",
    "        tf.keras.layers.Embedding(len(text_vectorizer.get_vocabulary()), 64, mask_zero=True),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        layers.Dense(lookup.vocabulary_size(), activation=\"sigmoid\"),\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Util Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_result(history, item):\n",
    "    plt.plot(history.history[item], label=item)\n",
    "    plt.plot(history.history[\"val_\" + item], label=\"val_\" + item)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(item)\n",
    "    plt.title(\"Train and Validation {} Over Epochs\".format(item), fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "def train_model(model, model_name, epochs=10, plot_metrics=False, optimizer=\"adam\"):\n",
    "    model.compile(\n",
    "    loss=\"binary_crossentropy\", \n",
    "    optimizer=\"adam\",\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy(),  \n",
    "             tf.keras.metrics.F1Score(average='macro'), \n",
    "             tf.keras.metrics.Precision(name='precision'),\n",
    "             tf.keras.metrics.Recall(name='recall')]\n",
    "    )   \n",
    "\n",
    "    early_stopping_monitor = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0,\n",
    "        patience=0,\n",
    "        verbose=0,\n",
    "        mode='auto',\n",
    "        baseline=None,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        train_dataset, validation_data=validation_dataset, epochs=epochs, callbacks=[early_stopping_monitor], verbose=1\n",
    "    )\n",
    "\n",
    "    if plot_metrics:\n",
    "        plot_result(history, \"loss\")\n",
    "        plot_result(history, \"binary_accuracy\")\n",
    "\n",
    "    metrics_values = model.evaluate(test_dataset)\n",
    "    metrics_names = model.metrics_names\n",
    "\n",
    "    result = {metrics_names[i]: metrics_values[i] for i in range(len(metrics_names))}\n",
    "\n",
    "    result[\"model_name\"] = model_name\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "262/262 [==============================] - 5s 17ms/step - loss: 0.3022 - binary_accuracy: 0.8954 - f1_score: 0.1410 - precision: 0.4964 - recall: 0.2417 - val_loss: 0.2272 - val_binary_accuracy: 0.9184 - val_f1_score: 0.2538 - val_precision: 0.6965 - val_recall: 0.3726\n",
      "Epoch 2/10\n",
      "262/262 [==============================] - 4s 16ms/step - loss: 0.1489 - binary_accuracy: 0.9439 - f1_score: 0.3729 - precision: 0.8289 - recall: 0.5821 - val_loss: 0.2302 - val_binary_accuracy: 0.9194 - val_f1_score: 0.2984 - val_precision: 0.6548 - val_recall: 0.4643\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.2272 - binary_accuracy: 0.9181 - f1_score: 0.2430 - precision: 0.6997 - recall: 0.3625\n"
     ]
    }
   ],
   "source": [
    "text_vectorizer = layers.TextVectorization(output_mode=\"tf_idf\")\n",
    "text_vectorizer.adapt(train_dataset.map(lambda text, label: text))\n",
    "\n",
    "model = make_mlp_model(text_vectorizer)\n",
    "\n",
    "result = train_model(model, \"mlp\")\n",
    "\n",
    "results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "262/262 [==============================] - 3s 5ms/step - loss: 0.2939 - binary_accuracy: 0.8936 - f1_score: 0.0342 - precision: 0.4174 - recall: 0.0518 - val_loss: 0.2837 - val_binary_accuracy: 0.8964 - val_f1_score: 0.0321 - val_precision: 0.4892 - val_recall: 0.0676\n",
      "Epoch 2/10\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.2863 - binary_accuracy: 0.8955 - f1_score: 0.0323 - precision: 0.4889 - recall: 0.0550 - val_loss: 0.2836 - val_binary_accuracy: 0.8961 - val_f1_score: 0.0321 - val_precision: 0.4870 - val_recall: 0.1053\n",
      "Epoch 3/10\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.2857 - binary_accuracy: 0.8954 - f1_score: 0.0322 - precision: 0.4829 - recall: 0.0483 - val_loss: 0.2834 - val_binary_accuracy: 0.8960 - val_f1_score: 0.0321 - val_precision: 0.4802 - val_recall: 0.0805\n",
      "Epoch 4/10\n",
      "262/262 [==============================] - 1s 3ms/step - loss: 0.2854 - binary_accuracy: 0.8958 - f1_score: 0.0322 - precision: 0.5026 - recall: 0.0370 - val_loss: 0.2849 - val_binary_accuracy: 0.8961 - val_f1_score: 0.0321 - val_precision: 0.4772 - val_recall: 0.0601\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2833 - binary_accuracy: 0.8970 - f1_score: 0.0320 - precision: 0.5085 - recall: 0.0841\n"
     ]
    }
   ],
   "source": [
    "max_seqlen = 150\n",
    "text_vectorizer = layers.TextVectorization(output_sequence_length=max_seqlen, output_mode=\"int\")\n",
    "text_vectorizer.adapt(train_dataset.map(lambda text, label: text))\n",
    "\n",
    "model = make_conv_model(text_vectorizer)\n",
    "\n",
    "result = train_model(model, \"conv\")\n",
    "\n",
    "results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "262/262 [==============================] - 26s 83ms/step - loss: 0.3132 - binary_accuracy: 0.8881 - f1_score: 0.0358 - precision: 0.2837 - recall: 0.0480 - val_loss: 0.2837 - val_binary_accuracy: 0.8967 - val_f1_score: 0.0321 - val_precision: 0.5833 - val_recall: 0.0018\n",
      "Epoch 2/10\n",
      "262/262 [==============================] - 12s 45ms/step - loss: 0.2763 - binary_accuracy: 0.8980 - f1_score: 0.0486 - precision: 0.5594 - recall: 0.1033 - val_loss: 0.2585 - val_binary_accuracy: 0.9015 - val_f1_score: 0.0622 - val_precision: 0.5793 - val_recall: 0.1690\n",
      "Epoch 3/10\n",
      "262/262 [==============================] - 8s 32ms/step - loss: 0.2438 - binary_accuracy: 0.9052 - f1_score: 0.1093 - precision: 0.6327 - recall: 0.2169 - val_loss: 0.2425 - val_binary_accuracy: 0.9069 - val_f1_score: 0.1324 - val_precision: 0.6441 - val_recall: 0.2210\n",
      "Epoch 4/10\n",
      "262/262 [==============================] - 6s 23ms/step - loss: 0.2212 - binary_accuracy: 0.9130 - f1_score: 0.1597 - precision: 0.6732 - recall: 0.3221 - val_loss: 0.2299 - val_binary_accuracy: 0.9107 - val_f1_score: 0.1685 - val_precision: 0.6563 - val_recall: 0.2856\n",
      "Epoch 5/10\n",
      "262/262 [==============================] - 6s 21ms/step - loss: 0.2008 - binary_accuracy: 0.9214 - f1_score: 0.2112 - precision: 0.7236 - recall: 0.3986 - val_loss: 0.2238 - val_binary_accuracy: 0.9142 - val_f1_score: 0.1912 - val_precision: 0.6396 - val_recall: 0.3874\n",
      "Epoch 6/10\n",
      "262/262 [==============================] - 5s 21ms/step - loss: 0.1840 - binary_accuracy: 0.9281 - f1_score: 0.2462 - precision: 0.7399 - recall: 0.4783 - val_loss: 0.2188 - val_binary_accuracy: 0.9164 - val_f1_score: 0.2195 - val_precision: 0.6445 - val_recall: 0.4253\n",
      "Epoch 7/10\n",
      "262/262 [==============================] - 5s 19ms/step - loss: 0.1714 - binary_accuracy: 0.9329 - f1_score: 0.2734 - precision: 0.7554 - recall: 0.5270 - val_loss: 0.2263 - val_binary_accuracy: 0.9159 - val_f1_score: 0.2237 - val_precision: 0.6487 - val_recall: 0.4059\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2196 - binary_accuracy: 0.9152 - f1_score: 0.2113 - precision: 0.6355 - recall: 0.4197\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = 10000\n",
    "text_vectorizer = layers.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE)\n",
    "text_vectorizer.adapt(train_dataset.map(lambda text, label: text))\n",
    "\n",
    "model = make_lstm_model(text_vectorizer)\n",
    "\n",
    "result = train_model(model, \"lstm\")\n",
    "\n",
    "results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "262/262 [==============================] - 27s 71ms/step - loss: 0.3459 - binary_accuracy: 0.8744 - f1_score: 0.0526 - precision: 0.2774 - recall: 0.1274 - val_loss: 0.2837 - val_binary_accuracy: 0.8967 - val_f1_score: 0.0321 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/10\n",
      "262/262 [==============================] - 12s 45ms/step - loss: 0.2928 - binary_accuracy: 0.8962 - f1_score: 0.0479 - precision: 0.5107 - recall: 0.1056 - val_loss: 0.2645 - val_binary_accuracy: 0.9016 - val_f1_score: 0.0562 - val_precision: 0.6132 - val_recall: 0.1299\n",
      "Epoch 3/10\n",
      "262/262 [==============================] - 9s 34ms/step - loss: 0.2687 - binary_accuracy: 0.9000 - f1_score: 0.0768 - precision: 0.5742 - recall: 0.1568 - val_loss: 0.2496 - val_binary_accuracy: 0.9044 - val_f1_score: 0.0860 - val_precision: 0.6188 - val_recall: 0.1944\n",
      "Epoch 4/10\n",
      "262/262 [==============================] - 8s 30ms/step - loss: 0.2485 - binary_accuracy: 0.9044 - f1_score: 0.1118 - precision: 0.6188 - recall: 0.2162 - val_loss: 0.2437 - val_binary_accuracy: 0.9052 - val_f1_score: 0.1075 - val_precision: 0.6388 - val_recall: 0.1901\n",
      "Epoch 5/10\n",
      "262/262 [==============================] - 8s 30ms/step - loss: 0.2379 - binary_accuracy: 0.9063 - f1_score: 0.1311 - precision: 0.6288 - recall: 0.2470 - val_loss: 0.2386 - val_binary_accuracy: 0.9060 - val_f1_score: 0.1231 - val_precision: 0.6277 - val_recall: 0.2219\n",
      "Epoch 6/10\n",
      "262/262 [==============================] - 7s 28ms/step - loss: 0.2302 - binary_accuracy: 0.9077 - f1_score: 0.1481 - precision: 0.6369 - recall: 0.2675 - val_loss: 0.2373 - val_binary_accuracy: 0.9066 - val_f1_score: 0.1458 - val_precision: 0.6204 - val_recall: 0.2477\n",
      "Epoch 7/10\n",
      "262/262 [==============================] - 7s 29ms/step - loss: 0.2226 - binary_accuracy: 0.9100 - f1_score: 0.1695 - precision: 0.6442 - recall: 0.3045 - val_loss: 0.2401 - val_binary_accuracy: 0.9076 - val_f1_score: 0.1494 - val_precision: 0.6281 - val_recall: 0.2600\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2388 - binary_accuracy: 0.9066 - f1_score: 0.1322 - precision: 0.6190 - recall: 0.2487\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = 10000\n",
    "text_vectorizer = layers.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE)\n",
    "text_vectorizer.adapt(train_dataset.map(lambda text, label: text))\n",
    "\n",
    "model = make_stacked_lstm_model(text_vectorizer)\n",
    "\n",
    "result = train_model(model, \"stacked_lstm\")\n",
    "\n",
    "results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from official.nlp import optimization  # to create AdamW optimizer\n",
    "from tfhub_maps import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier_model():\n",
    "  bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8'\n",
    "\n",
    "  tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
    "  tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
    "\n",
    "  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
    "  encoder_inputs = preprocessing_layer(text_input)\n",
    "  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
    "  outputs = encoder(encoder_inputs)\n",
    "  net = outputs['pooled_output']\n",
    "  net = tf.keras.layers.Dropout(0.1)(net)\n",
    "  net = tf.keras.layers.Dense(lookup.vocabulary_size(), activation=\"sigmoid\")(net)\n",
    "  return tf.keras.Model(text_input, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "262/262 [==============================] - 118s 421ms/step - loss: 0.2974 - binary_accuracy: 0.8925 - f1_score: 0.0409 - precision: 0.4308 - recall: 0.0980 - val_loss: 0.2871 - val_binary_accuracy: 0.8967 - val_f1_score: 0.0321 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/10\n",
      "262/262 [==============================] - 106s 403ms/step - loss: 0.2916 - binary_accuracy: 0.8945 - f1_score: 0.0359 - precision: 0.4660 - recall: 0.0825 - val_loss: 0.2868 - val_binary_accuracy: 0.8939 - val_f1_score: 0.0321 - val_precision: 0.4717 - val_recall: 0.2283\n",
      "Epoch 3/10\n",
      "262/262 [==============================] - 107s 410ms/step - loss: 0.2887 - binary_accuracy: 0.8948 - f1_score: 0.0328 - precision: 0.4687 - recall: 0.0707 - val_loss: 0.2851 - val_binary_accuracy: 0.8967 - val_f1_score: 0.0321 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/10\n",
      "262/262 [==============================] - 108s 411ms/step - loss: 0.2881 - binary_accuracy: 0.8951 - f1_score: 0.0325 - precision: 0.4775 - recall: 0.0646 - val_loss: 0.2843 - val_binary_accuracy: 0.8967 - val_f1_score: 0.0321 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/10\n",
      "262/262 [==============================] - 107s 408ms/step - loss: 0.2877 - binary_accuracy: 0.8950 - f1_score: 0.0324 - precision: 0.4708 - recall: 0.0548 - val_loss: 0.2843 - val_binary_accuracy: 0.8967 - val_f1_score: 0.0321 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/10\n",
      "262/262 [==============================] - 107s 408ms/step - loss: 0.2873 - binary_accuracy: 0.8950 - f1_score: 0.0324 - precision: 0.4680 - recall: 0.0513 - val_loss: 0.2845 - val_binary_accuracy: 0.8967 - val_f1_score: 0.0321 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "33/33 [==============================] - 8s 242ms/step - loss: 0.2844 - binary_accuracy: 0.8967 - f1_score: 0.0320 - precision: 0.0000e+00 - recall: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "steps_per_epoch = tf.data.experimental.cardinality(train_dataset).numpy()\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "num_warmup_steps = int(0.1*num_train_steps)\n",
    "\n",
    "init_lr = 3e-5\n",
    "\n",
    "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
    "                                          num_train_steps=num_train_steps,\n",
    "                                          num_warmup_steps=num_warmup_steps,\n",
    "                                          optimizer_type='adamw')\n",
    "\n",
    "model = build_classifier_model()\n",
    "\n",
    "result = train_model(model, \"bert\", optimizer=optimizer)\n",
    "\n",
    "results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "262/262 [==============================] - 114s 408ms/step - loss: 0.2969 - binary_accuracy: 0.8927 - f1_score: 0.0407 - precision: 0.4349 - recall: 0.0973 - val_loss: 0.2892 - val_binary_accuracy: 0.8939 - val_f1_score: 0.0321 - val_precision: 0.4717 - val_recall: 0.2283\n",
      "Epoch 2/10\n",
      "262/262 [==============================] - 101s 386ms/step - loss: 0.2905 - binary_accuracy: 0.8947 - f1_score: 0.0354 - precision: 0.4707 - recall: 0.0816 - val_loss: 0.2877 - val_binary_accuracy: 0.8967 - val_f1_score: 0.0321 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/10\n",
      "262/262 [==============================] - 102s 388ms/step - loss: 0.2888 - binary_accuracy: 0.8950 - f1_score: 0.0331 - precision: 0.4748 - recall: 0.0708 - val_loss: 0.2846 - val_binary_accuracy: 0.8939 - val_f1_score: 0.0321 - val_precision: 0.4717 - val_recall: 0.2283\n",
      "Epoch 4/10\n",
      "262/262 [==============================] - 101s 387ms/step - loss: 0.2878 - binary_accuracy: 0.8951 - f1_score: 0.0329 - precision: 0.4774 - recall: 0.0670 - val_loss: 0.2839 - val_binary_accuracy: 0.8967 - val_f1_score: 0.0321 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/10\n",
      "262/262 [==============================] - 101s 387ms/step - loss: 0.2875 - binary_accuracy: 0.8951 - f1_score: 0.0323 - precision: 0.4752 - recall: 0.0600 - val_loss: 0.2844 - val_binary_accuracy: 0.8939 - val_f1_score: 0.0321 - val_precision: 0.4717 - val_recall: 0.2283\n",
      "33/33 [==============================] - 8s 234ms/step - loss: 0.2840 - binary_accuracy: 0.8967 - f1_score: 0.0320 - precision: 0.0000e+00 - recall: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "model = build_classifier_model()\n",
    "\n",
    "result = train_model(model, \"berty\")\n",
    "\n",
    "results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>binary_accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>model_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.227237</td>\n",
       "      <td>0.918105</td>\n",
       "      <td>0.243036</td>\n",
       "      <td>0.699660</td>\n",
       "      <td>0.362516</td>\n",
       "      <td>mlp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.283308</td>\n",
       "      <td>0.897031</td>\n",
       "      <td>0.032038</td>\n",
       "      <td>0.508511</td>\n",
       "      <td>0.084145</td>\n",
       "      <td>conv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.219622</td>\n",
       "      <td>0.915221</td>\n",
       "      <td>0.211336</td>\n",
       "      <td>0.635507</td>\n",
       "      <td>0.419669</td>\n",
       "      <td>lstm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.238806</td>\n",
       "      <td>0.906617</td>\n",
       "      <td>0.132190</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.248680</td>\n",
       "      <td>stacked_lstm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.284396</td>\n",
       "      <td>0.896740</td>\n",
       "      <td>0.032038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>bert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.284039</td>\n",
       "      <td>0.896740</td>\n",
       "      <td>0.032038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>berty</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  binary_accuracy  f1_score  precision    recall    model_name\n",
       "0  0.227237         0.918105  0.243036   0.699660  0.362516           mlp\n",
       "1  0.283308         0.897031  0.032038   0.508511  0.084145          conv\n",
       "2  0.219622         0.915221  0.211336   0.635507  0.419669          lstm\n",
       "3  0.238806         0.906617  0.132190   0.619048  0.248680  stacked_lstm\n",
       "4  0.284396         0.896740  0.032038   0.000000  0.000000          bert\n",
       "5  0.284039         0.896740  0.032038   0.000000  0.000000         berty"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# model_dir = \"models/\"\n",
    "# model_name = \"model\"\n",
    "# model_version = \"1\"\n",
    "# model_export_path = f\"{model_dir}/{model_name}/{model_version}\"\n",
    "\n",
    "# invert_stringlookup_layer = tf.keras.layers.StringLookup(vocabulary=vocab, invert=True)\n",
    "\n",
    "# model_for_inference = keras.Sequential([model, \n",
    "#                                         layers.Lambda(lambda x: tf.round(x)),\n",
    "#                                         layers.Lambda(lambda x: tf.map_fn(lambda y: tf.where(y == 1.0)[..., 0] + 1, x, dtype=(tf.int64))),\n",
    "#                                         invert_stringlookup_layer\n",
    "#                                         ])\n",
    "\n",
    "# tf.saved_model.save(\n",
    "#     model_for_inference,\n",
    "#     export_dir=model_export_path,\n",
    "# )\n",
    "\n",
    "# print(f\"SavedModel files: {os.listdir(model_export_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "movies",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
